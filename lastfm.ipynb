{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = pd.read_csv('data/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('data/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into ap matrix\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity\n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(\"sparsity: %.2f\" % sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "particular-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 17632)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "falling-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "marine-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "np.random\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions, random_state=42)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southeast-accommodation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lightfm.data.Dataset object at 0x7f4774faf6a0>\n"
     ]
    }
   ],
   "source": [
    "print(Dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moral-illness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f4774faf640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp', random_state=42)\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legendary-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.38, test 0.13.\n",
      "AUC: train 0.97, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision1 = precision_at_k(model, train, k=10).mean()\n",
    "test_precision1 = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc1 = auc_score(model, train).mean()\n",
    "test_auc1 = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision1, test_precision1))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc1, test_auc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "educational-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17632\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(len(top_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "according-nylon",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-adf3103c7c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: len() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-greensboro",
   "metadata": {},
   "source": [
    "1. logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='logistic',random_state=42)\n",
    "model.fit(train, epochs=10, num_threads=2)\n",
    "\n",
    "# Evaluate\n",
    "train_precision2 = precision_at_k(model, train, k=10).mean()\n",
    "test_precision2 = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc2 = auc_score(model, train).mean()\n",
    "test_auc2 = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision2, test_precision2))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc2, test_auc2))\n",
    "\n",
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-people",
   "metadata": {},
   "source": [
    "2.bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='bpr',random_state=42)\n",
    "model.fit(train, epochs=10, num_threads=2)\n",
    "\n",
    "# Evaluate\n",
    "train_precision3 = precision_at_k(model, train, k=10).mean()\n",
    "test_precision3 = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc3 = auc_score(model, train).mean()\n",
    "test_auc3 = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision3, test_precision3))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc3, test_auc3))\n",
    "\n",
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-geology",
   "metadata": {},
   "source": [
    "3.warp-kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp-kos',random_state=42)\n",
    "model.fit(train, epochs=10, num_threads=2)\n",
    "\n",
    "# Evaluate\n",
    "train_precision3 = precision_at_k(model, train, k=10).mean()\n",
    "test_precision3 = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc3 = auc_score(model, train).mean()\n",
    "test_auc3 = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision3, test_precision3))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc3, test_auc3))\n",
    "\n",
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score():\n",
    "    df = pd.DataFrame(columns=[\"WARP\", \"LOGISTIC\", \"BPR\" ,\"KOS-WARP\" ])\n",
    "    loss = ['warp', 'logistic', 'bpr', 'warp-kos' ]\n",
    "\n",
    "    for i,j in enumerate(loss):\n",
    "\n",
    "        model = LightFM(learning_rate=0.05, loss= j,random_state=42)\n",
    "        model.fit(train, epochs=10, num_threads=2)\n",
    "        a = precision_at_k(model, train, k=5).mean()\n",
    "        b = precision_at_k(model, test, k=5, train_interactions=train).mean()\n",
    "        c = auc_score(model, train).mean()\n",
    "        d = auc_score(model, test, train_interactions=train).mean()\n",
    "        this_column = df.columns[i]\n",
    "        df[this_column] = [a,b,c,d]\n",
    "    return(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-screw",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-salem",
   "metadata": {},
   "source": [
    "Voici deux sous taches supplémentaire qui vont nous aider à evaluer/interpréter notre modéle, après l'obtention des tableaux de résultats :\n",
    "\n",
    "1. faire la fonction get_recommandation qui prend en entrée un User et renvoie les Artists recommandé (du meilleurs au moins bon au sens du score de recommandation)\n",
    "\n",
    "    2. get_ground_truth qui renvoie les artistes ecoutés par un utilisateur par ordre décroissant du playCountScaled\n",
    "\n",
    "Ceci nous permettra d\"evaluer qualitatement les résultats que retourne le modéle et le comparer avec la vérité terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id):\n",
    "    # initialize the model\n",
    "    model = LightFM(learning_rate=0.05, loss='bpr', random_state=42)\n",
    "    model.fit(train, epochs=10, num_threads=2)\n",
    "    # predict\n",
    "    scores = model.predict(user_id, np.arange(n_items))\n",
    "    top_items = artist_names[np.argsort(-scores)]\n",
    "    return(pd.DataFrame(top_items[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ground_truth qui renvoie les artistes ecoutés par un utilisateur par ordre décroissant du playCountScaled\n",
    "def get_ground_truth(user_id): \n",
    "    t = get_recommendations(user_id)\n",
    "    z = top_items.join(artist_rank, on=\"\")\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(user_id):\n",
    "    ground_ap = ap(user_id)(userID,name,playCountScaled)\n",
    "    ground_truth = ground.sort_values(by='playCountScaled', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ground_truth(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {'learning_schedule':['adagrad', 'adadelta'], \n",
    "              'loss':['warp', 'logistic','bpr','warp-kos'],\n",
    "             'random_state':[0, 42, 100]}\n",
    "params = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for grid in params:\n",
    "    model = LightFM(**grid)\n",
    "    pred = model.fit(train)\n",
    "    score.append(round(auc_score(model, train).mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.argmax(score)\n",
    "max_value_item = params[max_value].items()\n",
    "print(max_value)\n",
    "print(max_value_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "value =  dict()\n",
    "value[max_value] = max_value_item\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
